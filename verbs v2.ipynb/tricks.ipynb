{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "df3 = data_set['Pawpularity'] \n",
    "fig = px.histogram(df3, x=\"Pawpularity\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import plotly.express as px\n",
    "fig = px.box(df3, y=\"Pawpularity\")\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "number=data_set.loc[data_set.Pawpularity > 80 , 'Pawpularity'].count()\n",
    "(number/data_set.shape[0])*100\n",
    "#no need for hashing to select 0.2 of data since we won't be fetching new datasets\n",
    "#we do it again with sklearn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "train_set, test_set = train_test_split(data_set, test_size=0.2, random_state=42)\n",
    "##data is representative after a random split? Think not.\n",
    "# homogeneous data = strata; ensure that the test set is representative of the various categories of incomes in the whole dataset.\n",
    "#it kinda works somehow for pawpularity but we need ensurance for all categories\n",
    "data_set[\"pawtegory\"] = pd.cut(data_set[\"Pawpularity\"],\n",
    "bins=[0, 10, 20, 30, 40, 50, 60, 70, 80, 90,  np.inf],\n",
    "labels=[1, 2, 3, 4, 5,6,7,8,9,10])\n",
    "data_set[\"pawtegory\"].hist()\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "split= StratifiedShuffleSplit(n_splits=1, test_size=0.2, random_state=42)\n",
    "for train_index, test_index in split.split(data_set, data_set[\"pawtegory\"]):\n",
    "    strat_train_set = data_set.loc[train_index]\n",
    "    strat_test_set = data_set.loc[test_index]\n",
    "\n",
    "strat_test_set[\"pawtegory\"].value_counts() / len(strat_test_set)\n",
    "# lets compate it to our raw data\n",
    "data_set[\"pawtegory\"].value_counts() / len(data_set)\n",
    "#strat error\n",
    "((strat_test_set[\"pawtegory\"].value_counts() / len(strat_test_set)) -  (data_set[\"pawtegory\"].value_counts() / len(data_set)) )  *100\n",
    "\n",
    "# deleting pawtegory\n",
    "\n",
    "for set_ in (strat_train_set, strat_test_set):\n",
    "    set_.drop(\"pawtegory\", axis=1, inplace=True)\n",
    "    # Discover and Visualize the Data to Gain Insights\n",
    "cuteness= strat_train_set.copy()\n",
    "#couldnt visualize it with scatter\n",
    "# linear correlation\n",
    "corr_matrix = cuteness.corr()\n",
    "corr_matrix[\"Pawpularity\"].sort_values(ascending=False)\n",
    "#it proves that these data dont really have a huge influence on the pawpularity, \n",
    "#we should consider dimension reduction and merging features \n",
    "#correlation between attributes\n",
    "#'Subject Focus', 'Eyes', 'Face', 'Near', 'Action', 'Accessory','Group', 'Collage', 'Human', 'Occlusion', 'Info', 'Blur','Pawpularity'\n",
    "#copying into already named folders\n",
    "import shutil\n",
    "import os\n",
    "for name in strat_test_set[\"Id\"]:\n",
    "    file = os.path.join(r\"C:\\Users\\Yas\\Downloads\\petfinder-pawpularity-score\\train\", name + \".jpg\")\n",
    "    shutil.copy2( file, r\"C:\\Users\\Yas\\Desktop\\test\")\n",
    "\n",
    "\n",
    "for name in strat_train_set[\"Id\"]:\n",
    "    file = os.path.join(r\"C:\\Users\\Yas\\Downloads\\petfinder-pawpularity-score\\train\", name + \".jpg\")\n",
    "    shutil.copy2( file, r\"C:\\Users\\Yas\\Desktop\\train\")\n",
    "#separate the predictors and the labels\n",
    "\n",
    "\n",
    "cuteness= strat_train_set.drop([\"Pawpularity\", \"Id\"], axis=1)\n",
    "\n",
    "cuteness_label = strat_train_set[\"Pawpularity\"].copy()\n",
    "\n",
    "cuteness.info()\n",
    "\n",
    "    from sklearn.tree import DecisionTreeRegressor\n",
    "    tree_reg = DecisionTreeRegressor()\n",
    "    tree_reg.fit(cuteness, cuteness_label)\n",
    "\n",
    "from sklearn.metrics import mean_squared_error\n",
    "cuteness_predictions = tree_reg.predict(cuteness)\n",
    "tree_mse = mean_squared_error(cuteness_label, cuteness_predictions)\n",
    "tree_rmse = np.sqrt(tree_mse)\n",
    "tree_rmse\n",
    "\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "scores = cross_val_score(tree_reg, cuteness, cuteness_label, scoring=\"neg_mean_squared_error\", cv=10)\n",
    "tree_rmse_scores = np.sqrt(-scores)\n",
    "\n",
    "\n",
    "def display_scores(scores):\n",
    "    print(\"Scores:\", scores)\n",
    "    print(\"Mean:\", scores.mean())\n",
    "    print(\"Standard deviation:\", scores.std())\n",
    "display_scores(tree_rmse_scores)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
