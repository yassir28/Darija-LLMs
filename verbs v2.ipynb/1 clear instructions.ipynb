{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I. Towards writing clear instructions\n",
    "\n",
    "1. Towards a concise and detailed query.\n",
    "\n",
    "First prompt (simple) in English and Darija. Input is in Darija.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\"داق\" بالدارجة المغربية تعني \"to taste\" بالإنجليزية.\n",
      "To taste\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "def translate_verb(verb):\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages = [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"غادي نعطيك واحد الفعل بالدارجة المغربية، والمهمة ديالك هي تترجمو لنجليزية.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\", \n",
    "                \"content\": f\"{verb}\"\n",
    "            }\n",
    "        ],\n",
    "        temperature=0\n",
    "    )\n",
    "    return completion.choices[0].message.content\n",
    "\n",
    "def translate_verb1(verb):\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages = [\n",
    "            {\n",
    "                \"role\": \"system\",\n",
    "                \"content\": \"You will be provided with a verb in Moroccan Darija language, and your task is to translate it into English.\"\n",
    "            },\n",
    "            {\n",
    "                \"role\": \"user\", \n",
    "                \"content\": 'Verb: داق'\n",
    "            }\n",
    "                ],\n",
    "        temperature=0\n",
    "    )\n",
    "    return completion.choices[0].message.content\n",
    "\n",
    " # max_tokens=1, # in case of a dot\n",
    " # top_p=0.1\n",
    " # temperature: What sampling temperature to use, between 0 and 2. Higher values like 0.8 will make the output more random, while lower values like 0.2 will make it more focused and deterministic. We generally recommend altering this or top_p but not both.\n",
    " # top_p:An alternative to sampling with temperature, called nucleus sampling, where the model considers the results of the tokens with top_p probability mass. So 0.1 means only the tokens comprising the top 10% probability mass are considered.\n",
    " # max_tokens: The maximum number of tokens that can be generated in the chat completion.\n",
    "\n",
    "# to be included in report\n",
    "\n",
    "print(translate_verb('داق'))\n",
    "print(translate_verb1('داق'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "\n",
    "client = OpenAI()\n",
    "\n",
    "test = client.chat.completions.create(\n",
    "model =  \"gpt-3.5-turbo\",\n",
    "messages = [\n",
    "            {\"role\": \"system\", \"content\": \"نتا خبير فلهجة الدارجة المغربية وفالترجمة من الدارجة لنجليزية.\"},\n",
    "            {\"role\": \"user\", \"content\": \"ترجم الفعل المعطي بالدارجة المغربية لنجليزية كلمة بكلمة.\" + \n",
    "             \"مخصش يكون المخرج فعل مصدري. بلاما تعطي تفسيرات.\"},\n",
    "            {\"role\": \"assistant\", \"content\": \"واخا. فهمت. أنا مستعد للفعل\"},\n",
    "            {\"role\": \"user\", \"content\": f\"{verb}\"},\n",
    "],\n",
    "temperature=0, # deterministic\n",
    ")\n",
    "\n",
    "test2 = client.chat.completions.create(\n",
    "model =  \"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are an expert in Moroccan Darija dialect and in translating Darija to English.\"},\n",
    "            {\"role\": \"user\", \"content\": \"Translate the provided Moroccan Darija dialect verb into English using word-by-word translation.\" + \n",
    "             \"The output must not be an infinitive verb. No explanations are needed in the output\"},\n",
    "            {\"role\": \"assistant\", \"content\": \"OK, I understand. I am ready for the verb translation.\"},\n",
    "            {\"role\": \"user\", \"content\": f\"{verb}\"},\n",
    "        ],\n",
    "temperature=0, \n",
    "\n",
    "test = test.choices[0].message.content\n",
    "print(test)\n",
    "test2 = test2.choices[0].message.content\n",
    "print(test2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from openai import OpenAI\n",
    "import pandas as pd\n",
    "client = OpenAI()\n",
    "df = pd.read_csv('sentences.csv')\n",
    "\n",
    "\n",
    "def arb_prmpt_translate(verb):\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"You will be provided with a verb in Moroccan Darija language.\" + \n",
    "        \"Your task is to translate it into English and provide only its lemma as an output.\" + \n",
    "                    \"The lemma of the translated verb should not contain 'to'.\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\", \n",
    "        \"content\":  f'{verb}' \n",
    "    }\n",
    "            ], \n",
    "        temperature=0.1  \n",
    "        )\n",
    "    return completion.choices[0].message.content\n",
    "\n",
    "def eng_prmpt_translate(verb):\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "    {\n",
    "        \"role\": \"system\",\n",
    "        \"content\": \"You will be provided with a verb in Moroccan Darija language.\" + \n",
    "        \"Your task is to translate it into English and provide only its lemma as an output.\" + \n",
    "                    \"The lemma of the translated verb should not contain 'to'.\"\n",
    "    },\n",
    "    {\n",
    "        \"role\": \"user\", \n",
    "        \"content\":  f'{verb}' \n",
    "    }\n",
    "            ], \n",
    "        temperature=0.1  \n",
    "        # Deterministic responses\n",
    "        # max_tokens=1, # in case of a dot\n",
    "        )\n",
    "    return completion.choices[0].message.content\n",
    "df['transl'] = df['n1'].apply(translate)\n",
    "\n",
    "print(df['transl'])\n",
    "\n",
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "\n",
    "transl = df['transl']\n",
    "eng = df['eng']\n",
    "transl = [verb.replace(\" \", \"_\") for verb in transl]\n",
    "eng = [verb.replace(\" \", \"_\") for verb in eng]\n",
    "\n",
    "def max_path_similarity(word1, word2):\n",
    "    \"\"\"Calculate the maximum path similarity between two words.\"\"\"\n",
    "    synsets1 = wn.synsets(word1, pos=wn.VERB)\n",
    "    synsets2 = wn.synsets(word2, pos=wn.VERB)\n",
    "    max_score = 0\n",
    "    for syn1 in synsets1:\n",
    "        for syn2 in synsets2:\n",
    "            score = syn1.path_similarity(syn2)\n",
    "            if score and score > max_score:\n",
    "                max_score = score\n",
    "    return max_score\n",
    "# Calculate and print the path similarity for each pair of verbs with similar index\n",
    "\n",
    "def evaluate_pairs(threshold=0.5):\n",
    "    \"\"\"Evaluating each pair using WordNet path similarity and a threshold.\"\"\"\n",
    "    results = []\n",
    "    for i in range(len(transl)):\n",
    "        word1, word2 = transl[i], eng[i]\n",
    "        similarity = max_path_similarity(word1, word2)\n",
    "        results.append((i+2, word1, word2, similarity, similarity >= threshold))\n",
    "    return results\n",
    "results = evaluate_pairs()\n",
    "print(results)\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "similarities = [item[3] for item in results]\n",
    "\n",
    "# Calculate the average similarity\n",
    "average_similarity = sum(similarities) / len(similarities)\n",
    "\n",
    "# Print the result\n",
    "print(f'Average similarity: {average_similarity:.2f}%')\n",
    "\n",
    "\n",
    "# Define intervals of 10%\n",
    "intervals = [(i, i+10) for i in range(0, 90, 10)] + [(90, 101)]\n",
    "\n",
    "# Count similarities in each interval\n",
    "interval_counts = {interval: 0 for interval in intervals}\n",
    "for sim in similarities:\n",
    "    percentage = sim * 100  # Convert cosine similarity to percentage\n",
    "    for interval in intervals:\n",
    "        if interval[0] <= percentage < interval[1]:\n",
    "            interval_counts[interval] += 1\n",
    "            break\n",
    "\n",
    "\n",
    "\n",
    "# Count pairs in the interval 90-100%\n",
    "count_90_100 = interval_counts[(90, 101)]\n",
    "\n",
    "# Print the count for the interval 90-100%\n",
    "print(f'Count of pairs in the interval 90-100%: {count_90_100}')\n",
    "\n",
    "\n",
    "\n",
    "# Prepare data for plotting\n",
    "labels = [f'{interval[0]}-{interval[1]-1}' if interval[1] != 101 else '90-100' for interval in intervals]\n",
    "counts = [interval_counts[interval] for interval in intervals]\n",
    "\n",
    "# Plot bar chart\n",
    "plt.bar(labels, counts, color='skyblue')\n",
    "plt.xlabel('Similarity (%)')\n",
    "plt.ylabel('Count of pair verbs')\n",
    "plt.title('Similarity per interval')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.grid(True)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "chack previous work with stratified \n",
    "\n",
    "should the transliteration be any more checked within itself between the two results?\n",
    "\n",
    "there must be a clearance of all useless work.\n",
    "\n",
    "work from now on is with average. Makes sense than threshold."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
