{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "               n1          n2         n3  darija_ar          eng  \\\n",
      "0           9ahwa        9hwa      9ehwa       قهوة       coffee   \n",
      "1           korsi        krsi        NaN       كرسي        chair   \n",
      "2           tabla        tbla        NaN       طبلة        table   \n",
      "3             kas         NaN        NaN        كاس        glass   \n",
      "4              ma         lma        NaN        ماء        water   \n",
      "...           ...         ...        ...        ...          ...   \n",
      "1323  lizikottour  lizikotour  lizikotor  ليزيكوتور   headphones   \n",
      "1324     matiryal    mataryan   materiel   ماتيريال     hardware   \n",
      "1325      portabl    portable        NaN    پورتابل   cell phone   \n",
      "1326       maw3id      mou3id    maou3id       موعد  appointment   \n",
      "1327       reveil       revey     rrevey      ريفاي        alarm   \n",
      "\n",
      "                noun  \n",
      "0             Coffee  \n",
      "1              Chair  \n",
      "2               Drum  \n",
      "3                Cup  \n",
      "4              Water  \n",
      "...              ...  \n",
      "1323     Lizikoutour  \n",
      "1324       Materials  \n",
      "1325        Portable  \n",
      "1326     Appointment  \n",
      "1327  My countryside  \n",
      "\n",
      "[1328 rows x 6 columns]\n"
     ]
    }
   ],
   "source": [
    "from openai import OpenAI\n",
    "import pandas as pd\n",
    "\n",
    "# Initialize the OpenAI client\n",
    "client = OpenAI()\n",
    "\n",
    "df = pd.read_csv('nouns.csv')\n",
    "\n",
    "# Define a translation function using the OpenAI API\n",
    "def translate(noun):\n",
    "    completion = client.chat.completions.create(\n",
    "        model=\"gpt-3.5-turbo\",\n",
    "        messages=[\n",
    "            {\"role\": \"system\", \"content\": \"You are an expert in Moroccan Darija dialect and in translating Darija to English.\"},\n",
    "            {\"role\": \"user\", \"content\": \"Translate the provided Moroccan Darija dialect noun into English using word-by-word translation.\"},\n",
    "            {\"role\": \"assistant\", \"content\": \"OK, I understand. I am ready for the noun translation.\"},\n",
    "            {\"role\": \"user\", \"content\": \"ديما\"},\n",
    "            {\"role\": \"assistant\", \"content\": \"Always\"},\n",
    "            {\"role\": \"user\", \"content\":  f'{noun}' }\n",
    "\n",
    "        ],\n",
    "        temperature=0.1  # Deterministic responses\n",
    "    )\n",
    "    return completion.choices[0].message.content\n",
    "\n",
    "# Apply the translation function to the 'darija_ar' column\n",
    "df['noun'] = df['darija_ar'].apply(translate)\n",
    "\n",
    "# Display or save the resulting DataFrame\n",
    "print(df)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "ename": "IndexError",
     "evalue": "list index out of range",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mIndexError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[20], line 30\u001b[0m\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# Compare ith row in each column\u001b[39;00m\n\u001b[0;32m     29\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mrange\u001b[39m(\u001b[38;5;28mlen\u001b[39m(df)):\n\u001b[1;32m---> 30\u001b[0m     similarity \u001b[38;5;241m=\u001b[39m \u001b[43mcalculate_wup_similarity\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43meng\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdf\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mloc\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mnoun\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     31\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m similarity \u001b[38;5;129;01mand\u001b[39;00m similarity \u001b[38;5;241m>\u001b[39m\u001b[38;5;241m=\u001b[39m threshold:\n\u001b[0;32m     32\u001b[0m         matches \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n",
      "Cell \u001b[1;32mIn[20], line 15\u001b[0m, in \u001b[0;36mcalculate_wup_similarity\u001b[1;34m(word1, word2)\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mcalculate_wup_similarity\u001b[39m(word1, word2):\n\u001b[0;32m     13\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Calculate the maximum path similarity between two words.\"\"\"\u001b[39;00m\n\u001b[1;32m---> 15\u001b[0m     synset1 \u001b[38;5;241m=\u001b[39m \u001b[43mwn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msynsets\u001b[49m\u001b[43m(\u001b[49m\u001b[43mword1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpos\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mwn\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mNOUN\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[0;32m     16\u001b[0m     synset2 \u001b[38;5;241m=\u001b[39m wn\u001b[38;5;241m.\u001b[39msynsets(word2, pos\u001b[38;5;241m=\u001b[39mwn\u001b[38;5;241m.\u001b[39mNOUN)[\u001b[38;5;241m0\u001b[39m]\n\u001b[0;32m     17\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m synset1 \u001b[38;5;129;01mand\u001b[39;00m synset2:\n",
      "\u001b[1;31mIndexError\u001b[0m: list index out of range"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "from nltk.corpus import wordnet as wn\n",
    "\n",
    "eng = df['eng']\n",
    "transl = df['noun']\n",
    "\n",
    "#transl = [verb.replace(\" \", \"_\") for verb in transl]\n",
    "#eng = [verb.replace(\" \", \"_\") for verb in eng]\n",
    "\n",
    "\n",
    "\n",
    "def calculate_wup_similarity(word1, word2):\n",
    "    \"\"\"Calculate the maximum path similarity between two words.\"\"\"\n",
    "\n",
    "    synset1 = wn.synsets(word1, pos=wn.NOUN)[0]\n",
    "    synset2 = wn.synsets(word2, pos=wn.NOUN)[0]\n",
    "    if synset1 and synset2:\n",
    "        return synset1.wup_similarity(synset2)\n",
    "    return 0\n",
    "# Calculate and print the path similarity for each pair of verbs with similar index\n",
    "\n",
    "# Matching threshold\n",
    "threshold = 0.7\n",
    "matches = 0\n",
    "non_matches = 0\n",
    "\n",
    "\n",
    "# Compare ith row in each column\n",
    "for i in range(len(df)):\n",
    "    similarity = calculate_wup_similarity(df.loc[i, 'eng'], df.loc[i, 'noun'])\n",
    "    if similarity and similarity >= threshold:\n",
    "        matches += 1\n",
    "    else:\n",
    "        non_matches += 1\n",
    "\n",
    "# Total comparisons\n",
    "total_comparisons = len(df1) * len(df2)\n",
    "non_matches = total_comparisons - matches\n",
    "\n",
    "# Data for pie chart\n",
    "data = [matches, non_matches]\n",
    "labels = ['Match', 'No Match']\n",
    "\n",
    "# Create pie chart\n",
    "fig, ax = plt.subplots()\n",
    "ax.pie(data, labels=labels, autopct='%1.1f%%', startangle=90)\n",
    "ax.axis('equal')  # Equal aspect ratio ensures that pie is drawn as a circle.\n",
    "\n",
    "plt.title('Wu-Palmer Similarity Match vs. No Match')\n",
    "plt.show()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
